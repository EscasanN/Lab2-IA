{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876ed314",
   "metadata": {},
   "source": [
    "# Laboratorio 2 - IA\n",
    "\n",
    "## Autores\n",
    "\n",
    "Nelson Escalante\n",
    "\n",
    "Milton Polanco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4699b9",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f49cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificion optima por X:\n",
      "X = 1 -> Y = 1\n",
      "X = 2 -> Y = 0\n",
      "X = 3 -> Y = 0\n",
      "X = 4 -> Y = 1\n",
      "\n",
      "Error del clasificador: 0.31\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Array con los datos a clasificar, \n",
    "# con columnas X de 1 a 4 y filas Y de 0 a 1\n",
    "joint = np.array([\n",
    "    [0.09, 0.16, 0.17, 0.05],   # Y = 0\n",
    "    [0.15, 0.07, 0.10, 0.21]    # Y = 1\n",
    "])\n",
    "\n",
    "# Clasificador bayesiano optimo\n",
    "classifier = np.argmax(joint, axis=0)\n",
    "\n",
    "# Error bayesiano\n",
    "bayes_error = np.sum(np.min(joint, axis=0))\n",
    "\n",
    "print(\"Clasificion optima por X:\")\n",
    "for i, y in enumerate(classifier, start=1):\n",
    "    print(f\"X = {i} -> Y = {y}\")\n",
    "\n",
    "print(\"\\nError del clasificador:\", bayes_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82135eb9",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ebdbab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral x* = 0.5493061443340549\n",
      "Error Bayesiano = 0.3075499102701248\n"
     ]
    }
   ],
   "source": [
    "x_star = 0.5 * np.log(3)\n",
    "\n",
    "Pe = 0.5 * (np.exp(-3 * x_star) + (1 - np.exp(-x_star)))\n",
    "\n",
    "print(\"Umbral x* =\", x_star)\n",
    "print(\"Error Bayesiano =\", Pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe33236",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "653fd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.17.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mdax8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fefcabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones con KNN (k=3):\n",
      "  Caso 1: No\n",
      "  Caso 2: Yes\n",
      "Predicciones con Naïve Bayes:\n",
      "  Caso 1: No\n",
      "  Caso 2: Yes\n",
      "\n",
      "Métricas: KNN\n",
      "Accuracy:  0.8571\n",
      "Precision: 0.8889\n",
      "Recall:    0.8889\n",
      "F1 Score:  0.8889\n",
      "ROC AUC:   0.8556\n",
      "\n",
      "Métricas: Naïve Bayes\n",
      "Accuracy:  0.9286\n",
      "Precision: 0.9000\n",
      "Recall:    1.0000\n",
      "F1 Score:  0.9474\n",
      "ROC AUC:   0.9222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Preparación de los datos\n",
    "data = {\n",
    "    'Outlook': ['Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Sunny', 'Rainy', 'Overcast', 'Overcast', 'Sunny'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Windy': ['False', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'True'],\n",
    "    'PlayGolf': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Codificación de variables categóricas a numéricas\n",
    "encoders = {}\n",
    "for col in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "X = df.drop('PlayGolf', axis=1)\n",
    "y = df['PlayGolf']\n",
    "\n",
    "# 2. Casos a predecir\n",
    "# Caso 1: (Rainy, Hot, High, False)\n",
    "# Caso 2: (Sunny, Hot, Normal, False)\n",
    "x_test = pd.DataFrame([\n",
    "    ['Rainy', 'Hot', 'High', 'False'],\n",
    "    ['Sunny', 'Hot', 'Normal', 'False']\n",
    "], columns=['Outlook', 'Temperature', 'Humidity', 'Windy'])\n",
    "\n",
    "for col in x_test.columns:\n",
    "    x_test[col] = encoders[col].transform(x_test[col])\n",
    "\n",
    "# 3. Entrenamiento de modelos\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X, y)\n",
    "\n",
    "nb = CategoricalNB()\n",
    "nb.fit(X, y)\n",
    "\n",
    "# 4. Resultados de predicción\n",
    "pred_knn = knn.predict(x_test)\n",
    "pred_nb = nb.predict(x_test)\n",
    "\n",
    "def print_preds(preds, model_name):\n",
    "    print(f\"Predicciones con {model_name}:\")\n",
    "    for i, p in enumerate(preds):\n",
    "        label = encoders['PlayGolf'].inverse_transform([p])[0]\n",
    "        print(f\"  Caso {i+1}: {label}\")\n",
    "\n",
    "print_preds(pred_knn, \"KNN (k=3)\")\n",
    "print_preds(pred_nb, \"Naïve Bayes\")\n",
    "\n",
    "# 5. Evaluación de métricas (sobre el set de entrenamiento)\n",
    "def calcular_metricas(model, X, y, nombre):\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    print(f\"\\nMétricas: {nombre}\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC:   {roc_auc_score(y, y_proba):.4f}\")\n",
    "\n",
    "calcular_metricas(knn, X, y, \"KNN\")\n",
    "calcular_metricas(nb, X, y, \"Naïve Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5958322",
   "metadata": {},
   "source": [
    "### Comparación de resultados\n",
    "Al evaluar ambos modelos sobre el conjunto de datos de entrenamiento:\n",
    "* **Naïve Bayes:** suele presentar un desempeño más robusto en este problema clásico (Weather dataset), ya que las variables se asumen independientes y el modelo probabilístico captura bien la tendencia general a pesar del poco volumen de datos.\n",
    "* **KNN:** es más sensible a la escala y a la vecindad local. Con $k=3$, el modelo tiende a memorizar el ruido si los datos son escasos, aunque ofrece resultados muy similares en precisión para este caso específico.\n",
    "\n",
    "De acuerdo con las métricas obtenidas (Accuracy y ROC AUC), el clasificador de **Naïve Bayes** es preferible para este escenario por su estabilidad probabilística.\n",
    "\n",
    "### ¿Cómo construir un clasificador bueno con tan pocos datos?\n",
    "Para construir un clasificador eficiente cuando el dataset es pequeño (como este), se recomiendan las siguientes estrategias:\n",
    "1.  **Modelos con alto sesgo (High Bias):** Utilizar algoritmos simples como Naïve Bayes o Regresión Logística. Estos modelos no requieren grandes cantidades de datos para converger y son menos propensos al overfitting en muestras pequeñas.\n",
    "2.  **Validación Cruzada:** Emplear técnicas como Leave-One-Out Cross-Validation (LOOCV), donde se entrena el modelo N veces usando N-1 datos, asegurando que cada observación se use para validar.\n",
    "3.  **Reducción de dimensionalidad:** Mantener solo las variables más relevantes para evitar la \"maldición de la dimensionalidad\".\n",
    "4.  **Suavizado (Smoothing):** En el caso de Bayes, se recomienda usar suavizado de Laplace para evitar que probabilidades de cero invaliden el cálculo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
